(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.12717562913894653
aF0.9086233973503113
aF0.9642998576164246
aF0.977155864238739
aF0.9804192781448364
aF0.9844738841056824
asVtime/percentage_convergence_performance
p5
(lp6
F0.13997863233089447
aF0.9403954148292542
aF0.9910650253295898
aF0.9989152550697327
aF1.002585530281067
aF1.0040128231048584
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.1357792764902115
aF0.9121835231781006
aF0.9613330960273743
aF0.9689477682113647
aF0.972507894039154
aF0.9738923907279968
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I43
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.301356077194214
aF2.3017361164093018
aF2.2995705604553223
aF2.2975707054138184
aF2.2872860431671143
aF2.2901010513305664
aF2.277998447418213
aF2.265563726425171
aF2.2567248344421387
aF2.232341766357422
aF2.196516990661621
aF2.1376101970672607
aF2.115144729614258
aF2.0291213989257812
aF1.8977075815200806
aF1.7243012189865112
aF1.4279215335845947
aF1.1821569204330444
aF0.8076351284980774
aF0.8546653985977173
aF0.6859947443008423
aF0.7537683248519897
aF0.7508754730224609
aF0.8354731202125549
aF1.0597078800201416
aF0.6456819772720337
aF0.681760847568512
aF0.5241082310676575
aF0.5698779821395874
aF0.4288269281387329
aF0.41772323846817017
aF0.4398577809333801
aF0.4934441149234772
aF0.5853301882743835
aF0.4566786587238312
aF0.48204854130744934
aF0.4676692485809326
aF0.3178938031196594
aF0.40296101570129395
aF0.3495935797691345
aF0.4116552472114563
aF0.3553209602832794
aF0.17256589233875275
aF0.18841099739074707
aF0.2673321068286896
aF0.19086362421512604
aF0.3585827946662903
aF0.17104430496692657
aF0.3761206269264221
aF0.23439329862594604
aF0.2797657251358032
aF0.39816153049468994
aF0.40449559688568115
aF0.3089648485183716
aF0.18295890092849731
aF0.1752832531929016
aF0.3853529989719391
aF0.13681064546108246
aF0.31185227632522583
aF0.19789916276931763
aF0.1439436972141266
aF0.23995459079742432
aF0.22645513713359833
aF0.22746433317661285
aF0.25872600078582764
aF0.09801498800516129
aF0.21780797839164734
aF0.15041032433509827
aF0.19090807437896729
aF0.16813841462135315
aF0.14594480395317078
aF0.21367837488651276
aF0.2585133910179138
aF0.1828898787498474
aF0.16529443860054016
aF0.05404156818985939
aF0.15355822443962097
aF0.09635649621486664
aF0.23739001154899597
aF0.16950032114982605
aF0.19152992963790894
aF0.22644370794296265
aF0.12424521148204803
aF0.15710151195526123
aF0.13528385758399963
aF0.16620279848575592
aF0.16052716970443726
aF0.07264701277017593
aF0.10550415515899658
aF0.12998908758163452
aF0.16309754550457
aF0.11597268283367157
aF0.12928375601768494
aF0.0873754546046257
aF0.09436976909637451
aF0.06798691302537918
aF0.09721279889345169
aF0.1160842776298523
aF0.12291358411312103
aF0.18824756145477295
aF0.2065914273262024
aF0.1407082974910736
aF0.09451894462108612
aF0.179469034075737
aF0.12748874723911285
aF0.030486252158880234
aF0.09121783077716827
aF0.0856413021683693
aF0.08448135852813721
aF0.15508662164211273
aF0.06186690926551819
aF0.1153448298573494
aF0.1683504581451416
aF0.09680448472499847
aF0.07494281977415085
aF0.06463859230279922
aF0.051473021507263184
aF0.06081003323197365
aF0.07318861782550812
aF0.033244650810956955
aF0.12257364392280579
aF0.15817567706108093
aF0.06353449821472168
aF0.11169053614139557
aF0.12348748743534088
aF0.08547105640172958
aF0.051088202744722366
aF0.03494087606668472
aF0.1981571763753891
aF0.1008988618850708
aF0.1579277068376541
aF0.05385076627135277
aF0.07199329882860184
aF0.04147480055689812
aF0.023250054568052292
aF0.0293062012642622
aF0.03175056353211403
aF0.14137445390224457
aF0.11738970130681992
aF0.052981194108724594
aF0.03276806324720383
aF0.016168344765901566
aF0.027269583195447922
aF0.08462756872177124
aF0.08202183246612549
aF0.08871395885944366
aF0.037172649055719376
aF0.08148561418056488
aF0.06365848332643509
aF0.09137848019599915
aF0.06820288300514221
aF0.06386727094650269
aF0.053254760801792145
aF0.03272008150815964
aF0.07313727587461472
aF0.04318235442042351
aF0.07034356892108917
aF0.024295080453157425
aF0.01597481220960617
aF0.04458199441432953
aF0.05699644237756729
aF0.08126460760831833
aF0.043709855526685715
aF0.016361039131879807
aF0.10723915696144104
aF0.07085206359624863
aF0.030881311744451523
aF0.09473562240600586
aF0.018207978457212448
aF0.174200639128685
aF0.04994077607989311
aF0.09222747385501862
aF0.0279711727052927
aF0.06957802176475525
aF0.08881491422653198
aF0.04895564168691635
aF0.07407338917255402
aF0.11205659806728363
aF0.01611580327153206
aF0.06626127660274506
aF0.03500320017337799
aF0.05617208033800125
aF0.016020357608795166
aF0.04992629587650299
aF0.0642358735203743
aF0.04721131920814514
aF0.03116658516228199
aF0.09737209975719452
aF0.09400773793458939
aF0.0812423825263977
aF0.062498949468135834
aF0.09914661943912506
aF0.05362233892083168
aF0.017378373071551323
aF0.0619649775326252
aF0.07167494297027588
aF0.048727087676525116
aF0.09672799706459045
aF0.07214698195457458
aF0.022355088964104652
aF0.06157957762479782
aF0.03376229852437973
aF0.03530484437942505
aF0.04043745622038841
aF0.047526951879262924
aF0.03836412727832794
aF0.059778615832328796
aF0.04064449667930603
aF0.04102678224444389
aF0.06215439364314079
aF0.08444684743881226
aF0.03211783245205879
aF0.04117893800139427
aF0.08995446562767029
aF0.017419101670384407
aF0.012511448934674263
aF0.048584405332803726
aF0.013806445524096489
aF0.047856640070676804
aF0.02495628595352173
aF0.03361797332763672
aF0.038382574915885925
aF0.03803316876292229
aF0.052921123802661896
aF0.04544566944241524
aF0.07486128062009811
aF0.04589109867811203
aF0.04961314797401428
aF0.082718126475811
aF0.10300517827272415
aF0.02411409467458725
aF0.016033487394452095
aF0.16937454044818878
aF0.06308303773403168
aF0.011784715577960014
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3018314838409424
aF0.32048001885414124
aF0.11396137624979019
aF0.08161523193120956
aF0.06435750424861908
aF0.05015822499990463
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.301553249359131
aF0.3187044858932495
aF0.12432844936847687
aF0.10063690692186356
aF0.09166161715984344
aF0.08444689959287643
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF0.0
aF4.0
aF4.0
as.