(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.11669303476810455
aF0.9137658476829529
aF0.9667721390724182
aF0.9758702516555786
aF0.9836827516555786
aF0.9879351258277893
asVtime/percentage_convergence_performance
p5
(lp6
F0.11326748877763748
aF0.9436578154563904
aF0.9916767477989197
aF0.9997308254241943
aF1.003197193145752
aF1.003808856010437
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.10986946523189545
aF0.9153481125831604
aF0.9619264006614685
aF0.9697389006614685
aF0.9731012582778931
aF0.9736946225166321
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I44
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.3021984100341797
aF2.3014025688171387
aF2.2988994121551514
aF2.2952892780303955
aF2.291440010070801
aF2.2869176864624023
aF2.2803585529327393
aF2.269937753677368
aF2.2531626224517822
aF2.2244842052459717
aF2.18983793258667
aF2.1806833744049072
aF2.0926167964935303
aF2.011624813079834
aF1.8674845695495605
aF1.675342082977295
aF1.3266916275024414
aF1.2004574537277222
aF1.0600944757461548
aF0.9002389907836914
aF0.7950807809829712
aF0.6603596806526184
aF0.9191370010375977
aF0.8158785104751587
aF0.6385350227355957
aF0.654019832611084
aF0.9326614737510681
aF0.6437795162200928
aF0.46220070123672485
aF0.6213856935501099
aF0.4499507546424866
aF0.6292901039123535
aF0.38726550340652466
aF0.4892573058605194
aF0.6077303886413574
aF0.3529494106769562
aF0.4136056900024414
aF0.6964436173439026
aF0.3497734069824219
aF0.48311468958854675
aF0.3040262758731842
aF0.18281422555446625
aF0.29635971784591675
aF0.2594524323940277
aF0.29325413703918457
aF0.19038352370262146
aF0.19670787453651428
aF0.3307880461215973
aF0.2413913607597351
aF0.21310892701148987
aF0.2643367052078247
aF0.17250189185142517
aF0.21045932173728943
aF0.36309659481048584
aF0.16046428680419922
aF0.2500866651535034
aF0.37871766090393066
aF0.19399097561836243
aF0.13541561365127563
aF0.2266491949558258
aF0.14750832319259644
aF0.1820656955242157
aF0.1702398955821991
aF0.23769040405750275
aF0.3069314658641815
aF0.1980261206626892
aF0.16237904131412506
aF0.1442672312259674
aF0.15194886922836304
aF0.19600370526313782
aF0.18535932898521423
aF0.3329501748085022
aF0.1068083643913269
aF0.26135534048080444
aF0.23843024671077728
aF0.13679702579975128
aF0.18289461731910706
aF0.1916574388742447
aF0.11734431982040405
aF0.15652525424957275
aF0.13216182589530945
aF0.1776723861694336
aF0.06275604665279388
aF0.25995302200317383
aF0.1144179254770279
aF0.16032612323760986
aF0.16383641958236694
aF0.06051783263683319
aF0.14958418905735016
aF0.12466691434383392
aF0.16496022045612335
aF0.16613246500492096
aF0.18244986236095428
aF0.11477919667959213
aF0.07385239005088806
aF0.17415618896484375
aF0.09950676560401917
aF0.20100900530815125
aF0.08196235448122025
aF0.06615739315748215
aF0.10689912736415863
aF0.06649190932512283
aF0.05845973640680313
aF0.0945698544383049
aF0.05622384697198868
aF0.10452838242053986
aF0.0692845806479454
aF0.06131485477089882
aF0.0638231560587883
aF0.0760994553565979
aF0.15479744970798492
aF0.13415154814720154
aF0.13221298158168793
aF0.06548629701137543
aF0.1379099190235138
aF0.10513000935316086
aF0.18046188354492188
aF0.049851685762405396
aF0.1519290804862976
aF0.02393954060971737
aF0.0749829113483429
aF0.07702672481536865
aF0.07220813632011414
aF0.1590535193681717
aF0.040123991668224335
aF0.05536193400621414
aF0.07665055990219116
aF0.09191595017910004
aF0.055204249918460846
aF0.11761759221553802
aF0.09997986257076263
aF0.04482504725456238
aF0.1268455982208252
aF0.07943306863307953
aF0.155196413397789
aF0.04284731298685074
aF0.08668309450149536
aF0.054269939661026
aF0.055342257022857666
aF0.08975545316934586
aF0.07908141613006592
aF0.08041828125715256
aF0.20436660945415497
aF0.028108619153499603
aF0.08578924834728241
aF0.06491853296756744
aF0.020446809008717537
aF0.012422459200024605
aF0.12462472915649414
aF0.0602625347673893
aF0.044734884053468704
aF0.020464375615119934
aF0.13305215537548065
aF0.1007414236664772
aF0.05121879652142525
aF0.032779842615127563
aF0.05049050599336624
aF0.10717720538377762
aF0.08441214263439178
aF0.021400421857833862
aF0.13632412254810333
aF0.062200210988521576
aF0.04898495972156525
aF0.034231703728437424
aF0.10828238725662231
aF0.02037820778787136
aF0.09737152606248856
aF0.1656837910413742
aF0.03916441276669502
aF0.11271240562200546
aF0.06349000334739685
aF0.022742711007595062
aF0.05388954281806946
aF0.05285340175032616
aF0.044241130352020264
aF0.0627945140004158
aF0.09069106727838516
aF0.11432841420173645
aF0.07293231040239334
aF0.035443227738142014
aF0.059247300028800964
aF0.07936166971921921
aF0.0467803031206131
aF0.05603519827127457
aF0.02858876623213291
aF0.05924701690673828
aF0.032336462289094925
aF0.18995089828968048
aF0.10652270913124084
aF0.06067543476819992
aF0.08272236585617065
aF0.029932528734207153
aF0.04628504067659378
aF0.06031268090009689
aF0.07158097624778748
aF0.018003255128860474
aF0.1569727510213852
aF0.04471966251730919
aF0.045308176428079605
aF0.02996203675866127
aF0.012013228610157967
aF0.02142910100519657
aF0.0352969616651535
aF0.07336577028036118
aF0.10470336675643921
aF0.07506914436817169
aF0.04976319521665573
aF0.0313858725130558
aF0.018891597166657448
aF0.009549594484269619
aF0.05809524282813072
aF0.0084658432751894
aF0.0961538627743721
aF0.03721889480948448
aF0.038341015577316284
aF0.053008902817964554
aF0.07880730926990509
aF0.01571088284254074
aF0.013830804266035557
aF0.07421746104955673
aF0.05695294588804245
aF0.04122644662857056
aF0.005740462802350521
aF0.03152674064040184
aF0.07926899194717407
aF0.055357109755277634
aF0.006192539818584919
aF0.04993702843785286
aF0.017479071393609047
aF0.011738437227904797
aF0.003960596863180399
aF0.034184861928224564
aF0.05397903919219971
aF0.049099475145339966
aF0.018225006759166718
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3022801876068115
aF0.29003602266311646
aF0.10954414308071136
aF0.07437682896852493
aF0.05077321082353592
aF0.040345486253499985
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.3024251461029053
aF0.2725751996040344
aF0.12047129124403
aF0.09726326912641525
aF0.0866500735282898
aF0.08304386585950851
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF0.0
aF4.0
aF4.0
as.