(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.14102056622505188
aF0.9680577516555786
aF0.9817048907279968
aF0.9841772317886353
aF0.9859572649002075
aF0.9872428774833679
asVhyperparams/learning_rate
p5
(lp6
F0.0015848929760977626
aF0.0015848929760977626
aF0.0015848929760977626
aF0.0015848929760977626
aF0.0015848929760977626
aF0.0015848929760977626
asVtime/percentage_convergence_performance
p7
(lp8
F0.1448722779750824
aF0.9944294095039368
aF1.0071732997894287
aF1.0041147470474243
aF1.0047264099121094
aF1.008294701576233
asVcheckpoint/checkpoint_test_acc
p9
(lp10
F0.14052610099315643
aF0.9645965099334717
aF0.9769580960273743
aF0.9739912748336792
aF0.9745846390724182
aF0.9780458807945251
asS'training/training_steps'
p11
(lp12
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p13
(lp14
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p15
ccopy_reg
_reconstructor
p16
(cargparse
Namespace
p17
c__builtin__
object
p18
Ntp19
Rp20
(dp21
S'wd'
p22
NsS'data_dir'
p23
S'data_tfobs'
p24
sS'epsilon'
p25
F1e-08
sS'nologs'
p26
I00
sS'num_epochs'
p27
I5
sS'lr_sched_epochs'
p28
NsS'saveto'
p29
S'res/benchmark_small_final/'
p30
sS'lr_sched_factors'
p31
NsS'train_log_interval'
p32
I10
sS'checkpoint_epochs'
p33
I1
sS'print_train_iter'
p34
I00
sS'lr'
p35
F0.001584893
sS'beta2'
p36
F0.999
sS'beta1'
p37
F0.9
sS'bs'
p38
I128
sS'pickle'
p39
I01
sS'random_seed'
p40
I50
sS'no_time'
p41
I00
sS'test_problem'
p42
S'mnist.mnist_mlp'
p43
sS'run_name'
p44
S'Adam/'
p45
sbsVhyperparams/beta2
p46
(lp47
F0.9990000128746033
aF0.9990000128746033
aF0.9990000128746033
aF0.9990000128746033
aF0.9990000128746033
aF0.9990000128746033
asVtraining/training_loss
p48
(lp49
F2.3020145893096924
aF1.128532886505127
aF0.65069979429245
aF0.5056301355361938
aF0.5315288305282593
aF0.38871341943740845
aF0.34806180000305176
aF0.5406935214996338
aF0.30192679166793823
aF0.4000968039035797
aF0.18098053336143494
aF0.27693265676498413
aF0.3031960725784302
aF0.1562316119670868
aF0.2107139527797699
aF0.3886929154396057
aF0.24625515937805176
aF0.2092948704957962
aF0.18805471062660217
aF0.25217702984809875
aF0.2215031087398529
aF0.19766446948051453
aF0.11965656280517578
aF0.15901294350624084
aF0.1880001425743103
aF0.10188829898834229
aF0.17382213473320007
aF0.23559238016605377
aF0.176069974899292
aF0.16280719637870789
aF0.12399662286043167
aF0.2093990445137024
aF0.1820196807384491
aF0.14767423272132874
aF0.15835188329219818
aF0.10691307485103607
aF0.16853001713752747
aF0.1143665611743927
aF0.08341296762228012
aF0.11668269336223602
aF0.0861218124628067
aF0.08671213686466217
aF0.15058206021785736
aF0.07223883271217346
aF0.13224461674690247
aF0.23070545494556427
aF0.13390383124351501
aF0.09001386165618896
aF0.1308511197566986
aF0.060494132339954376
aF0.08957289159297943
aF0.15063264966011047
aF0.10821859538555145
aF0.15837281942367554
aF0.05834425985813141
aF0.22403010725975037
aF0.16615161299705505
aF0.11327357590198517
aF0.09183649718761444
aF0.02195301651954651
aF0.09500724822282791
aF0.050101153552532196
aF0.053650010377168655
aF0.09362247586250305
aF0.1223611980676651
aF0.07457864284515381
aF0.07174509018659592
aF0.1853598803281784
aF0.06435027718544006
aF0.08856436610221863
aF0.07885828614234924
aF0.07068924605846405
aF0.10335230827331543
aF0.359118789434433
aF0.10448947548866272
aF0.12670418620109558
aF0.09589546173810959
aF0.07264603674411774
aF0.0892263650894165
aF0.06383489072322845
aF0.07211054861545563
aF0.18126830458641052
aF0.04810165986418724
aF0.04483982175588608
aF0.06119491904973984
aF0.08464150130748749
aF0.02036980912089348
aF0.04787585884332657
aF0.06606768816709518
aF0.03747393563389778
aF0.1147950142621994
aF0.05360933393239975
aF0.13299621641635895
aF0.05525193735957146
aF0.03582758828997612
aF0.10471462458372116
aF0.09144337475299835
aF0.04099113494157791
aF0.07486026734113693
aF0.06106536090373993
aF0.04427139088511467
aF0.04476446658372879
aF0.004943791311234236
aF0.18200138211250305
aF0.07932398468255997
aF0.0329597145318985
aF0.044591326266527176
aF0.09590248763561249
aF0.03695809096097946
aF0.04185117781162262
aF0.09930072724819183
aF0.10003921389579773
aF0.08254887163639069
aF0.14726582169532776
aF0.03953391686081886
aF0.0582834929227829
aF0.020564476028084755
aF0.017604665830731392
aF0.037948478013277054
aF0.05718488246202469
aF0.06312984973192215
aF0.05489278584718704
aF0.0217460785061121
aF0.03973628208041191
aF0.057265665382146835
aF0.08930706977844238
aF0.11685136705636978
aF0.18519547581672668
aF0.089437335729599
aF0.07967976480722427
aF0.07269275188446045
aF0.027132559567689896
aF0.04218222573399544
aF0.06614086776971817
aF0.030399370938539505
aF0.023801162838935852
aF0.044811926782131195
aF0.04741835966706276
aF0.04886585474014282
aF0.0642729178071022
aF0.05184594914317131
aF0.07772880792617798
aF0.09954854846000671
aF0.050682321190834045
aF0.16084033250808716
aF0.11783420294523239
aF0.06831081211566925
aF0.04966290295124054
aF0.08394603431224823
aF0.07702580094337463
aF0.11627197265625
aF0.01573537476360798
aF0.05004437267780304
aF0.05604720115661621
aF0.021830052137374878
aF0.07750263065099716
aF0.09092052280902863
aF0.028425801545381546
aF0.041402291506528854
aF0.012142912484705448
aF0.018708277493715286
aF0.029270000755786896
aF0.025665123015642166
aF0.011984100565314293
aF0.06793984025716782
aF0.038737647235393524
aF0.03668506443500519
aF0.029146745800971985
aF0.08732244372367859
aF0.027901597321033478
aF0.005181910004466772
aF0.08940718322992325
aF0.07253430783748627
aF0.06563781201839447
aF0.04262686148285866
aF0.03942039608955383
aF0.07150480896234512
aF0.011405890807509422
aF0.10241986811161041
aF0.03524485602974892
aF0.0961846113204956
aF0.006796385161578655
aF0.03938555344939232
aF0.010424230247735977
aF0.0025862576439976692
aF0.013324817642569542
aF0.06800653785467148
aF0.011553897522389889
aF0.01153293251991272
aF0.05179924890398979
aF0.045883260667324066
aF0.016800280660390854
aF0.003872656263411045
aF0.007005590945482254
aF0.010016371496021748
aF0.07034943997859955
aF0.03812753036618233
aF0.015528758987784386
aF0.0884903073310852
aF0.01091837789863348
aF0.012115053832530975
aF0.038078565150499344
aF0.03732103109359741
aF0.04846608638763428
aF0.044879570603370667
aF0.026269763708114624
aF0.023412862792611122
aF0.013885663822293282
aF0.04484992474317551
aF0.07094366103410721
aF0.1234331801533699
aF0.0043835812248289585
aF0.061517324298620224
aF0.027288611978292465
aF0.05696035176515579
aF0.037843070924282074
aF0.022451326251029968
aF0.009506722912192345
aF0.1744595766067505
aF0.0034497869201004505
aF0.06271094083786011
aF0.03115776553750038
aF0.011561291292309761
aF0.02542274445295334
aF0.020614175125956535
aF0.05210895463824272
aF0.005831053014844656
aF0.0039426423609256744
aF0.026496196165680885
aF0.052836962044239044
aF0.013683527708053589
aF0.03372266888618469
aF0.01079125702381134
aF0.003125299932435155
aF0.13113462924957275
asVcheckpoint/checkpoint_train_loss
p50
(lp51
F2.3011279106140137
aF0.10390625894069672
aF0.05971725657582283
aF0.05455419793725014
aF0.04775054380297661
aF0.037101875990629196
asVhyperparams/beta1
p52
(lp53
F0.8999999761581421
aF0.8999999761581421
aF0.8999999761581421
aF0.8999999761581421
aF0.8999999761581421
aF0.8999999761581421
asVcheckpoint/checkpoint_test_loss
p54
(lp55
F2.3012073040008545
aF0.11206959187984467
aF0.07953205704689026
aF0.09782717376947403
aF0.09672354906797409
aF0.08587861806154251
asVtime/convergence_iterations
p56
(lp57
F0.0
aF0.0
aF2.0
aF2.0
aF2.0
aF2.0
as.