(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.10828718543052673
aF0.9096123576164246
aF0.964695394039154
aF0.9785403609275818
aF0.984968364238739
aF0.9852650165557861
asVtime/percentage_convergence_performance
p5
(lp6
F0.1074562817811966
aF0.9422305226325989
aF0.9899435639381409
aF1.0011581182479858
aF1.0034010410308838
aF1.003095269203186
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.10423259437084198
aF0.9139636158943176
aF0.9602452516555786
aF0.9711233973503113
aF0.9732990264892578
aF0.9730023741722107
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I49
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.303356647491455
aF2.300903797149658
aF2.3001303672790527
aF2.2989602088928223
aF2.294321060180664
aF2.2925631999969482
aF2.2889485359191895
aF2.2805275917053223
aF2.266191005706787
aF2.2670812606811523
aF2.242112636566162
aF2.2094333171844482
aF2.147977828979492
aF2.0805435180664062
aF2.0529303550720215
aF1.9397711753845215
aF1.6776139736175537
aF1.3728981018066406
aF1.1460494995117188
aF0.8212584257125854
aF0.6954020261764526
aF0.887997567653656
aF0.7323160171508789
aF0.8168368339538574
aF0.6507905721664429
aF0.9242218732833862
aF1.1623597145080566
aF1.0721464157104492
aF0.7355048060417175
aF0.46465030312538147
aF0.5513216853141785
aF0.39913666248321533
aF0.4948466420173645
aF0.5727813839912415
aF0.6787687540054321
aF0.544324517250061
aF0.47651612758636475
aF0.37089505791664124
aF0.31108754873275757
aF0.4641564190387726
aF0.4107127785682678
aF0.2939581274986267
aF0.34587693214416504
aF0.3651813566684723
aF0.46440398693084717
aF0.45209169387817383
aF0.2632450461387634
aF0.2705739736557007
aF0.25270822644233704
aF0.43675434589385986
aF0.39191821217536926
aF0.21447080373764038
aF0.2628411650657654
aF0.26978322863578796
aF0.19166123867034912
aF0.23680783808231354
aF0.28085118532180786
aF0.1908372938632965
aF0.23677654564380646
aF0.2019781768321991
aF0.20195333659648895
aF0.24290615320205688
aF0.1866409182548523
aF0.1911429911851883
aF0.2801690697669983
aF0.1053682267665863
aF0.09973374009132385
aF0.1309482753276825
aF0.17546363174915314
aF0.15111568570137024
aF0.19560137391090393
aF0.2028530389070511
aF0.1344696283340454
aF0.1519671082496643
aF0.1813589334487915
aF0.1995423585176468
aF0.17316767573356628
aF0.09642335772514343
aF0.1347893625497818
aF0.1655300110578537
aF0.12473984062671661
aF0.09577712416648865
aF0.1713728904724121
aF0.18170751631259918
aF0.2648583650588989
aF0.08804383873939514
aF0.14057153463363647
aF0.17551305890083313
aF0.23064596951007843
aF0.12367213517427444
aF0.10190390050411224
aF0.15582020580768585
aF0.1800740659236908
aF0.08421840518712997
aF0.07642017304897308
aF0.13115020096302032
aF0.161077618598938
aF0.10148430615663528
aF0.041529640555381775
aF0.08325305581092834
aF0.05825705826282501
aF0.11422275006771088
aF0.08413977921009064
aF0.07973439991474152
aF0.19184383749961853
aF0.11028466373682022
aF0.11529069393873215
aF0.10626381635665894
aF0.07691409438848495
aF0.12643514573574066
aF0.05022013187408447
aF0.2621752619743347
aF0.09144549071788788
aF0.109047070145607
aF0.09082681685686111
aF0.13868632912635803
aF0.10417971760034561
aF0.058520205318927765
aF0.15193358063697815
aF0.09259574115276337
aF0.12192277610301971
aF0.1413675844669342
aF0.1986790895462036
aF0.13394209742546082
aF0.11835840344429016
aF0.09264184534549713
aF0.039261870086193085
aF0.08589331060647964
aF0.12688153982162476
aF0.09213501960039139
aF0.19257359206676483
aF0.04904486611485481
aF0.09996841847896576
aF0.0910121351480484
aF0.04003928601741791
aF0.1378355324268341
aF0.09362253546714783
aF0.12875694036483765
aF0.12134513258934021
aF0.14486868679523468
aF0.05121041089296341
aF0.08520378172397614
aF0.07360265403985977
aF0.0339665487408638
aF0.04207883030176163
aF0.05104926973581314
aF0.052935272455215454
aF0.06265505403280258
aF0.12126807868480682
aF0.10260648280382156
aF0.060839660465717316
aF0.11687882989645004
aF0.08115042001008987
aF0.07409542798995972
aF0.13396483659744263
aF0.08055004477500916
aF0.09375061839818954
aF0.07441955804824829
aF0.10555163025856018
aF0.06795980036258698
aF0.08948066830635071
aF0.12673789262771606
aF0.12957021594047546
aF0.09591448307037354
aF0.03296554088592529
aF0.0544852614402771
aF0.057992443442344666
aF0.08402210474014282
aF0.05802730843424797
aF0.038341253995895386
aF0.05528798699378967
aF0.0752401277422905
aF0.03798992559313774
aF0.06301230192184448
aF0.018726788461208344
aF0.09536902606487274
aF0.038195639848709106
aF0.04682189226150513
aF0.06890081614255905
aF0.07092714309692383
aF0.09743185341358185
aF0.0720764547586441
aF0.022536521777510643
aF0.03610555827617645
aF0.017814764752984047
aF0.03462495654821396
aF0.03508400917053223
aF0.04889664798974991
aF0.029201187193393707
aF0.044872574508190155
aF0.06249892711639404
aF0.02985815703868866
aF0.08291225880384445
aF0.018385332077741623
aF0.05397805944085121
aF0.07523074001073837
aF0.02857894077897072
aF0.059493113309144974
aF0.023144496604800224
aF0.05262788012623787
aF0.13728131353855133
aF0.08063162863254547
aF0.03785237669944763
aF0.06830532848834991
aF0.0508682057261467
aF0.06652525067329407
aF0.073383629322052
aF0.021826062351465225
aF0.07020966708660126
aF0.04369191825389862
aF0.07629119604825974
aF0.04378591850399971
aF0.07304710149765015
aF0.05907582864165306
aF0.01941033825278282
aF0.037604521960020065
aF0.09247683733701706
aF0.025225266814231873
aF0.02000008523464203
aF0.06963210552930832
aF0.06825520098209381
aF0.020456615835428238
aF0.01765906810760498
aF0.11447237432003021
aF0.06820002943277359
aF0.04017329216003418
aF0.034503109753131866
aF0.02303428389132023
aF0.03044429048895836
aF0.023473691195249557
aF0.041385918855667114
aF0.0412454754114151
aF0.0461120679974556
aF0.08105328679084778
aF0.02631806582212448
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3028128147125244
aF0.30976226925849915
aF0.1127936914563179
aF0.0736197978258133
aF0.05275082588195801
aF0.045989084988832474
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.3028457164764404
aF0.2930801808834076
aF0.12343841046094894
aF0.09610355645418167
aF0.08554527163505554
aF0.0918634682893753
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF3.0
aF3.0
aF3.0
as.