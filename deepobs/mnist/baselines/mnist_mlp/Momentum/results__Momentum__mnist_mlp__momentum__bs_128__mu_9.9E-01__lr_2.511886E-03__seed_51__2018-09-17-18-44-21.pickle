(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.0947389230132103
aF0.9117879867553711
aF0.9617286324501038
aF0.9745846390724182
aF0.9824960231781006
aF0.9891218543052673
asVtime/percentage_convergence_performance
p5
(lp6
F0.10021776705980301
aF0.9489592909812927
aF0.9908611178398132
aF1.0023815631866455
aF1.007581114768982
aF1.0101298093795776
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.09721123427152634
aF0.9204905033111572
aF0.9611352682113647
aF0.9723101258277893
aF0.9773536324501038
aF0.9798259735107422
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I51
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.303905487060547
aF2.3024213314056396
aF2.3000383377075195
aF2.298145055770874
aF2.2917709350585938
aF2.2894904613494873
aF2.2860465049743652
aF2.279433012008667
aF2.2631187438964844
aF2.2576987743377686
aF2.226062536239624
aF2.1993658542633057
aF2.140096664428711
aF2.069565773010254
aF1.931167721748352
aF1.738431692123413
aF1.56614089012146
aF1.2858027219772339
aF1.0627901554107666
aF0.9053981304168701
aF0.7260847091674805
aF0.7980427145957947
aF0.5825369358062744
aF0.7120595574378967
aF0.8706004619598389
aF0.5929305553436279
aF0.6326988339424133
aF0.5460999011993408
aF0.48297765851020813
aF0.4670240581035614
aF0.268471360206604
aF0.354543536901474
aF0.5612500309944153
aF0.5559218525886536
aF0.3973035216331482
aF0.343669593334198
aF0.48965728282928467
aF0.4488227367401123
aF0.32198482751846313
aF0.2540667653083801
aF0.429473340511322
aF0.2931342124938965
aF0.3144116997718811
aF0.3156922459602356
aF0.35415732860565186
aF0.3113633394241333
aF0.29184815287590027
aF0.16584409773349762
aF0.22110332548618317
aF0.19476298987865448
aF0.25203078985214233
aF0.3521868586540222
aF0.28834474086761475
aF0.24914319813251495
aF0.1987743377685547
aF0.2889730930328369
aF0.42282992601394653
aF0.272693932056427
aF0.20998482406139374
aF0.16516804695129395
aF0.20497208833694458
aF0.17735593020915985
aF0.26416948437690735
aF0.3263719379901886
aF0.2771387994289398
aF0.33916348218917847
aF0.22497989237308502
aF0.19835039973258972
aF0.18527166545391083
aF0.16720625758171082
aF0.3087906241416931
aF0.30756473541259766
aF0.19421660900115967
aF0.17676801979541779
aF0.11394203454256058
aF0.2186027318239212
aF0.08985969424247742
aF0.1954430639743805
aF0.14781412482261658
aF0.1486411988735199
aF0.10457145422697067
aF0.2181100696325302
aF0.3155888319015503
aF0.22561602294445038
aF0.08576004207134247
aF0.2144073098897934
aF0.09426693618297577
aF0.16798436641693115
aF0.1713162660598755
aF0.11342373490333557
aF0.15299203991889954
aF0.1230834424495697
aF0.0527690127491951
aF0.0546417236328125
aF0.14701050519943237
aF0.14169421792030334
aF0.1627725064754486
aF0.14709344506263733
aF0.09597517549991608
aF0.23099148273468018
aF0.04419982060790062
aF0.1161508560180664
aF0.1519264280796051
aF0.1039322018623352
aF0.0824093222618103
aF0.12098361551761627
aF0.11214351654052734
aF0.09382808208465576
aF0.06396814435720444
aF0.07285356521606445
aF0.1140313372015953
aF0.06738115847110748
aF0.18835335969924927
aF0.07674412429332733
aF0.12040358781814575
aF0.18998850882053375
aF0.09552741050720215
aF0.14698456227779388
aF0.044784996658563614
aF0.10511910915374756
aF0.14646197855472565
aF0.1103440374135971
aF0.12170761823654175
aF0.10475089401006699
aF0.06946514546871185
aF0.17959699034690857
aF0.13349074125289917
aF0.05977649241685867
aF0.07080093026161194
aF0.027881238609552383
aF0.11106106638908386
aF0.24196645617485046
aF0.05662114545702934
aF0.07887330651283264
aF0.0687531977891922
aF0.12050275504589081
aF0.112341970205307
aF0.046035900712013245
aF0.039215266704559326
aF0.05420362204313278
aF0.03628957271575928
aF0.05729864910244942
aF0.05846481770277023
aF0.05198827385902405
aF0.04278052970767021
aF0.1259038895368576
aF0.07529473304748535
aF0.11650608479976654
aF0.08562597632408142
aF0.07363235950469971
aF0.07803427428007126
aF0.090787872672081
aF0.05000023543834686
aF0.08827228844165802
aF0.025185681879520416
aF0.03292607516050339
aF0.05310682952404022
aF0.042486704885959625
aF0.05748879164457321
aF0.06973955780267715
aF0.07722359150648117
aF0.09584516286849976
aF0.04709721356630325
aF0.061540648341178894
aF0.10168474912643433
aF0.06043783575296402
aF0.07840804010629654
aF0.0436474084854126
aF0.048222895711660385
aF0.06249001622200012
aF0.10226002335548401
aF0.07641028612852097
aF0.03266347199678421
aF0.059555888175964355
aF0.09318143874406815
aF0.028404440730810165
aF0.021149329841136932
aF0.05966360867023468
aF0.06977498531341553
aF0.031187810003757477
aF0.03002786450088024
aF0.04180508852005005
aF0.051195695996284485
aF0.07785361260175705
aF0.07042034715414047
aF0.07680825144052505
aF0.03593612462282181
aF0.028333095833659172
aF0.07914794981479645
aF0.11458319425582886
aF0.06344172358512878
aF0.04916998744010925
aF0.02218320593237877
aF0.1488414853811264
aF0.1179504469037056
aF0.011196085251867771
aF0.03634314239025116
aF0.014819718897342682
aF0.03022647835314274
aF0.04667244851589203
aF0.0809248685836792
aF0.021062523126602173
aF0.08727075904607773
aF0.02929190918803215
aF0.04531154781579971
aF0.027429688721895218
aF0.010077779181301594
aF0.03276898339390755
aF0.10078947991132736
aF0.05043138563632965
aF0.06586292386054993
aF0.03730028122663498
aF0.03289208188652992
aF0.03566770255565643
aF0.04067380726337433
aF0.03745128586888313
aF0.02068755403161049
aF0.011667799204587936
aF0.026634100824594498
aF0.09344392269849777
aF0.035135120153427124
aF0.016498086974024773
aF0.0397530198097229
aF0.019001537933945656
aF0.06817687302827835
aF0.023872077465057373
aF0.018710223957896233
aF0.034598805010318756
aF0.00956914946436882
aF0.0671907439827919
aF0.0486597940325737
aF0.06068374961614609
aF0.08502084016799927
aF0.09842022508382797
aF0.004773661494255066
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.303316831588745
aF0.2997779846191406
aF0.1251954585313797
aF0.07571282982826233
aF0.053021419793367386
aF0.03419090434908867
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.3030788898468018
aF0.2743000388145447
aF0.12197208404541016
aF0.08861476182937622
aF0.0779968872666359
aF0.06773241609334946
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF3.0
aF3.0
aF3.0
as.