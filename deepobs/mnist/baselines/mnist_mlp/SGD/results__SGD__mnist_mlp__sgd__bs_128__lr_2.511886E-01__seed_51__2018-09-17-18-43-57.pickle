(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.0947389230132103
aF0.9203916192054749
aF0.9371044039726257
aF0.9445213675498962
aF0.9453125
aF0.9910996556282043
asVtime/percentage_convergence_performance
p5
(lp6
F0.10021776705980301
aF0.9523236751556396
aF0.9602758288383484
aF0.9685338735580444
aF0.9683299660682678
aF1.0068674087524414
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.09721123427152634
aF0.9237539768218994
aF0.931467592716217
aF0.9394778609275818
aF0.939280092716217
aF0.9766613841056824
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'train_log_interval'
p23
I10
sS'nologs'
p24
I00
sS'num_epochs'
p25
I5
sS'lr_sched_epochs'
p26
NsS'saveto'
p27
S'res/benchmark_small_final/'
p28
sS'lr_sched_factors'
p29
NsS'run_name'
p30
S'SGD/'
p31
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.2511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I51
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sbsVtraining/training_loss
p41
(lp42
F2.303905487060547
aF2.2912793159484863
aF2.2426323890686035
aF2.127140998840332
aF1.6810293197631836
aF1.4441030025482178
aF1.129307508468628
aF1.1395044326782227
aF0.7655614614486694
aF0.5972893238067627
aF0.6202511787414551
aF0.49203306436538696
aF0.663673996925354
aF0.5786306858062744
aF0.48090484738349915
aF0.5116478204727173
aF0.4448026418685913
aF0.4468207359313965
aF0.3623157739639282
aF0.38549473881721497
aF0.2520062029361725
aF0.25543272495269775
aF0.3289472460746765
aF0.28737348318099976
aF0.26515766978263855
aF0.2951701283454895
aF0.29010263085365295
aF0.1365436613559723
aF0.21715010702610016
aF0.24382616579532623
aF0.1119476780295372
aF0.1792001873254776
aF0.23516999185085297
aF0.2789221405982971
aF0.18535618484020233
aF0.14838868379592896
aF0.31164640188217163
aF0.19721269607543945
aF0.15534594655036926
aF0.15412774682044983
aF0.256765216588974
aF0.1782759130001068
aF0.1907728761434555
aF0.17568838596343994
aF0.14428488910198212
aF0.16473835706710815
aF0.20789922773838043
aF0.1348344385623932
aF0.13106396794319153
aF0.12111900746822357
aF0.13876691460609436
aF0.1871623396873474
aF0.1399209052324295
aF0.13224640488624573
aF0.10313139855861664
aF0.2227943241596222
aF0.25855129957199097
aF0.17940329015254974
aF0.08457210659980774
aF0.09482347965240479
aF0.12603774666786194
aF0.07100331783294678
aF0.19930051267147064
aF0.2181151658296585
aF0.1440284699201584
aF0.2237282693386078
aF0.10300664603710175
aF0.09529958665370941
aF0.17167198657989502
aF0.1505938321352005
aF0.13719767332077026
aF0.2514198422431946
aF0.1135852262377739
aF0.07579721510410309
aF0.07523685693740845
aF0.13819894194602966
aF0.05148931220173836
aF0.10991080105304718
aF0.1607377976179123
aF0.09656308591365814
aF0.0670584887266159
aF0.17358368635177612
aF0.1993047297000885
aF0.17444726824760437
aF0.14343242347240448
aF0.15879784524440765
aF0.046866677701473236
aF0.11419952660799026
aF0.12624990940093994
aF0.10730171948671341
aF0.13083381950855255
aF0.04790806397795677
aF0.031268227845430374
aF0.04043574258685112
aF0.07897429168224335
aF0.0789978876709938
aF0.10447918623685837
aF0.08222928643226624
aF0.09241783618927002
aF0.14929957687854767
aF0.03302402049303055
aF0.1186121478676796
aF0.07232718914747238
aF0.09463304281234741
aF0.06184860318899155
aF0.05432435870170593
aF0.09088779985904694
aF0.07342731952667236
aF0.02385925129055977
aF0.05266084522008896
aF0.09774260222911835
aF0.033572204411029816
aF0.11068965494632721
aF0.07730782777070999
aF0.05390341579914093
aF0.14527571201324463
aF0.07592348754405975
aF0.10123063623905182
aF0.026726990938186646
aF0.07633543759584427
aF0.09513964504003525
aF0.08823442459106445
aF0.07737889885902405
aF0.0730067789554596
aF0.022614821791648865
aF0.13113753497600555
aF0.10478196293115616
aF0.03690444305539131
aF0.06895896792411804
aF0.029576050117611885
aF0.09467253088951111
aF0.25711917877197266
aF0.049857839941978455
aF0.05870195850729942
aF0.036437783390283585
aF0.05345864221453667
aF0.11739002913236618
aF0.040622398257255554
aF0.03054310381412506
aF0.04642070084810257
aF0.027584709227085114
aF0.02879919484257698
aF0.04390742629766464
aF0.048207059502601624
aF0.04016132280230522
aF0.09396988153457642
aF0.07348670065402985
aF0.08850264549255371
aF0.03560589998960495
aF0.0923641100525856
aF0.029035400599241257
aF0.04893077537417412
aF0.05684635415673256
aF0.05257243290543556
aF0.005897077731788158
aF0.031145233660936356
aF0.025352653115987778
aF0.05248767137527466
aF0.0338059738278389
aF0.057008787989616394
aF0.06461581587791443
aF0.05323302373290062
aF0.03821447864174843
aF0.021006502211093903
aF0.11073941737413406
aF0.08598215132951736
aF0.05993925780057907
aF0.048458606004714966
aF0.04075954481959343
aF0.019591592252254486
aF0.08400766551494598
aF0.03511366248130798
aF0.01762526109814644
aF0.026375189423561096
aF0.13142281770706177
aF0.011249399743974209
aF0.01061297208070755
aF0.04032185301184654
aF0.03368160128593445
aF0.030524447560310364
aF0.03665320947766304
aF0.0362112894654274
aF0.05333492159843445
aF0.04115333408117294
aF0.060310713946819305
aF0.053209953010082245
aF0.013949058949947357
aF0.025050872936844826
aF0.0699528157711029
aF0.1160886287689209
aF0.024095769971609116
aF0.05293232575058937
aF0.03689463064074516
aF0.10789398849010468
aF0.06316028535366058
aF0.022004583850502968
aF0.02022274024784565
aF0.022465869784355164
aF0.012339901179075241
aF0.018601100891828537
aF0.06596136093139648
aF0.016476435586810112
aF0.04322723299264908
aF0.013334476388990879
aF0.012852220796048641
aF0.01458728313446045
aF0.011110175400972366
aF0.019408751279115677
aF0.0738980695605278
aF0.0441097691655159
aF0.05234045907855034
aF0.02221802994608879
aF0.010266642086207867
aF0.02155018225312233
aF0.040557704865932465
aF0.026256226003170013
aF0.03148312494158745
aF0.008947843685746193
aF0.007230144459754229
aF0.06250995397567749
aF0.059779245406389236
aF0.01560564711689949
aF0.023834601044654846
aF0.0090855797752738
aF0.05916815996170044
aF0.010474721901118755
aF0.008202629163861275
aF0.054693084210157394
aF0.004774303175508976
aF0.02628656104207039
aF0.05747956782579422
aF0.06543292105197906
aF0.08344574272632599
aF0.10217325389385223
aF0.005850827321410179
asVcheckpoint/checkpoint_train_loss
p43
(lp44
F2.303316831588745
aF0.25128182768821716
aF0.19478322565555573
aF0.1697995364665985
aF0.17050625383853912
aF0.028017941862344742
asVcheckpoint/checkpoint_test_loss
p45
(lp46
F2.3030788898468018
aF0.2365512102842331
aF0.20457042753696442
aF0.19502508640289307
aF0.20472095906734467
aF0.07389314472675323
asVhyperparams/learning_rate
p47
(lp48
F0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
asVtime/convergence_iterations
p49
(lp50
F0.0
aF0.0
aF0.0
aF0.0
aF0.0
aF5.0
as.