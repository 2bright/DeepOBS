(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.1217365488409996
aF0.9151503443717957
aF0.965585470199585
aF0.9770569801330566
aF0.9824960231781006
aF0.9895173907279968
asVtime/percentage_convergence_performance
p5
(lp6
F0.11754942685365677
aF0.943861722946167
aF0.989331841468811
aF0.9975898861885071
aF1.0018718242645264
aF1.0079889297485352
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.11402294039726257
aF0.9155458807945251
aF0.9596518874168396
aF0.9676621556282043
aF0.9718156456947327
aF0.977749228477478
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I48
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.3020853996276855
aF2.3019967079162598
aF2.2980337142944336
aF2.2955009937286377
aF2.2910256385803223
aF2.281799793243408
aF2.2732768058776855
aF2.274176836013794
aF2.259552001953125
aF2.241116523742676
aF2.212010145187378
aF2.191636085510254
aF2.1043176651000977
aF2.0446698665618896
aF1.8678604364395142
aF1.5924322605133057
aF1.479356050491333
aF0.9990795254707336
aF1.033954381942749
aF0.9093733429908752
aF0.850972056388855
aF0.8704954385757446
aF0.8577411770820618
aF0.5737059116363525
aF0.8642081022262573
aF0.6279840469360352
aF0.6198441982269287
aF1.096353530883789
aF0.532974123954773
aF0.5048888921737671
aF0.3808850347995758
aF0.3524853587150574
aF0.37571144104003906
aF0.5877865552902222
aF0.4276401102542877
aF0.6626667976379395
aF0.4440772533416748
aF0.23820433020591736
aF0.3251502215862274
aF0.4643178880214691
aF0.1933092176914215
aF0.24842038750648499
aF0.33046817779541016
aF0.2630169093608856
aF0.3478516936302185
aF0.18151503801345825
aF0.2697752118110657
aF0.18515606224536896
aF0.5046852827072144
aF0.17575013637542725
aF0.2053019404411316
aF0.2676291763782501
aF0.31570300459861755
aF0.2731359302997589
aF0.30886638164520264
aF0.20994532108306885
aF0.19951075315475464
aF0.19054588675498962
aF0.2439926117658615
aF0.29224076867103577
aF0.25564125180244446
aF0.20503851771354675
aF0.10105226188898087
aF0.2596847712993622
aF0.13894037902355194
aF0.2805561423301697
aF0.20991912484169006
aF0.16338083148002625
aF0.15990713238716125
aF0.17030079662799835
aF0.09665822982788086
aF0.16250015795230865
aF0.19491726160049438
aF0.2281063199043274
aF0.203025683760643
aF0.12751033902168274
aF0.1335248202085495
aF0.21532930433750153
aF0.12791824340820312
aF0.11688679456710815
aF0.1484518051147461
aF0.09875008463859558
aF0.12026030570268631
aF0.1136428564786911
aF0.11029418557882309
aF0.07037270069122314
aF0.09012076258659363
aF0.09987665712833405
aF0.05901024490594864
aF0.12628944218158722
aF0.11238843202590942
aF0.11209198832511902
aF0.05933722108602524
aF0.16036203503608704
aF0.1732165366411209
aF0.19111111760139465
aF0.16266131401062012
aF0.09355054795742035
aF0.11763650178909302
aF0.061864398419857025
aF0.0935758724808693
aF0.10594227910041809
aF0.1881512850522995
aF0.09468474239110947
aF0.17707887291908264
aF0.15562787652015686
aF0.14485758543014526
aF0.09125746786594391
aF0.13117840886116028
aF0.09191131591796875
aF0.07543321698904037
aF0.11901774257421494
aF0.13031503558158875
aF0.0905994176864624
aF0.07284461706876755
aF0.08191923797130585
aF0.053171731531620026
aF0.07089321315288544
aF0.12005769461393356
aF0.09449214488267899
aF0.07776109129190445
aF0.06296420097351074
aF0.05412420630455017
aF0.17665770649909973
aF0.1750785857439041
aF0.06407155841588974
aF0.23962968587875366
aF0.11460784077644348
aF0.11282332241535187
aF0.1473499834537506
aF0.12441950291395187
aF0.06741993874311447
aF0.08752793073654175
aF0.11874216049909592
aF0.12836094200611115
aF0.0856405571103096
aF0.08248189091682434
aF0.0752968043088913
aF0.04875314235687256
aF0.08723604679107666
aF0.026552163064479828
aF0.04872894659638405
aF0.1247318834066391
aF0.03865775093436241
aF0.07644736021757126
aF0.03745683282613754
aF0.11259535700082779
aF0.03947591781616211
aF0.07456055283546448
aF0.0811302438378334
aF0.15419743955135345
aF0.12306062877178192
aF0.0703752189874649
aF0.07997391372919083
aF0.1265336573123932
aF0.08891211450099945
aF0.03957566246390343
aF0.0965108573436737
aF0.1387408971786499
aF0.021501556038856506
aF0.05627736076712608
aF0.1399359554052353
aF0.05009663105010986
aF0.10932309925556183
aF0.05346059426665306
aF0.04996495693922043
aF0.07690463960170746
aF0.036748260259628296
aF0.09225088357925415
aF0.05914450064301491
aF0.032044969499111176
aF0.06907305121421814
aF0.06275102496147156
aF0.06953977048397064
aF0.07558110356330872
aF0.10872228443622589
aF0.1861928105354309
aF0.03413598611950874
aF0.0952993780374527
aF0.07144483923912048
aF0.03867792338132858
aF0.06386470049619675
aF0.09332844614982605
aF0.09970906376838684
aF0.03715047985315323
aF0.05349256843328476
aF0.041555944830179214
aF0.08911328762769699
aF0.11878205090761185
aF0.10123009234666824
aF0.0613611601293087
aF0.09787553548812866
aF0.07472016662359238
aF0.022028403356671333
aF0.046059202402830124
aF0.05732335150241852
aF0.09050919115543365
aF0.024713894352316856
aF0.04018023610115051
aF0.03911306709051132
aF0.01596270129084587
aF0.04178810492157936
aF0.016459593549370766
aF0.06464724242687225
aF0.11333306133747101
aF0.08075995743274689
aF0.07384728640317917
aF0.0502706877887249
aF0.033989422023296356
aF0.07207129150629044
aF0.0652662143111229
aF0.09089472889900208
aF0.03409552574157715
aF0.009780319407582283
aF0.015510104596614838
aF0.04558012634515762
aF0.09834232181310654
aF0.06724141538143158
aF0.09529922902584076
aF0.010880951769649982
aF0.07153761386871338
aF0.08912115544080734
aF0.12548565864562988
aF0.09486537426710129
aF0.09700248390436172
aF0.011804120615124702
aF0.040430255234241486
aF0.053381726145744324
aF0.10536287724971771
aF0.0468052476644516
aF0.04815056920051575
aF0.0444067157804966
aF0.05091777443885803
aF0.045797042548656464
aF0.05947687476873398
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3032240867614746
aF0.27540597319602966
aF0.11112857609987259
aF0.07416688650846481
aF0.05962841957807541
aF0.037282511591911316
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.303661346435547
aF0.2725253999233246
aF0.12633323669433594
aF0.10169913619756699
aF0.08839437365531921
aF0.07548996061086655
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF0.0
aF4.0
aF4.0
as.