(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.12480221688747406
aF0.9190071225166321
aF0.9679588675498962
aF0.9800237417221069
aF0.9839794039726257
aF0.9893196225166321
asVtime/percentage_convergence_performance
p5
(lp6
F0.13121084868907928
aF0.9518139362335205
aF0.9889240264892578
aF0.9994249939918518
aF1.0019737482070923
aF1.0051342248916626
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.1272745281457901
aF0.9232594966888428
aF0.9592563509941101
aF0.9694422483444214
aF0.971914529800415
aF0.9749802350997925
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I46
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.3016233444213867
aF2.300574779510498
aF2.299912929534912
aF2.2973341941833496
aF2.2919297218322754
aF2.2812304496765137
aF2.2733211517333984
aF2.2804646492004395
aF2.2516045570373535
aF2.221251964569092
aF2.191073417663574
aF2.15486741065979
aF2.0359058380126953
aF1.8332970142364502
aF1.8058936595916748
aF1.5499217510223389
aF1.2036770582199097
aF1.0859873294830322
aF0.8286443948745728
aF0.7092509865760803
aF0.5907577276229858
aF1.1318756341934204
aF0.7799041271209717
aF0.9738606810569763
aF0.520782470703125
aF0.8301676511764526
aF0.96376633644104
aF0.7529919147491455
aF0.5403742790222168
aF0.4341038465499878
aF0.4964543282985687
aF0.46534496545791626
aF0.460089772939682
aF0.5559589862823486
aF0.4358956515789032
aF0.25425994396209717
aF0.43648332357406616
aF0.4059275984764099
aF0.2912431061267853
aF0.6140505075454712
aF0.2372964322566986
aF0.270640105009079
aF0.3713594079017639
aF0.3255613446235657
aF0.23801977932453156
aF0.2868303060531616
aF0.34761255979537964
aF0.5364346504211426
aF0.29003167152404785
aF0.33435964584350586
aF0.18674850463867188
aF0.23542247712612152
aF0.22559387981891632
aF0.14903835952281952
aF0.420181006193161
aF0.2586340606212616
aF0.27414488792419434
aF0.2687356770038605
aF0.28989487886428833
aF0.17011824250221252
aF0.24579942226409912
aF0.17538008093833923
aF0.18454714119434357
aF0.1606299877166748
aF0.16314829885959625
aF0.22114145755767822
aF0.1964079588651657
aF0.2754031717777252
aF0.26732560992240906
aF0.24976852536201477
aF0.23039835691452026
aF0.06986481696367264
aF0.19853462278842926
aF0.11507819592952728
aF0.26328667998313904
aF0.1232333853840828
aF0.20640680193901062
aF0.17354559898376465
aF0.2635270953178406
aF0.1765708327293396
aF0.2197893261909485
aF0.1516323685646057
aF0.16325950622558594
aF0.08230505883693695
aF0.09823835641145706
aF0.17740629613399506
aF0.08969639986753464
aF0.14339679479599
aF0.08327899873256683
aF0.05767519399523735
aF0.11346154659986496
aF0.2545001208782196
aF0.12537795305252075
aF0.06847946345806122
aF0.08795567601919174
aF0.07248448580503464
aF0.180543914437294
aF0.1551307737827301
aF0.10004210472106934
aF0.2291402518749237
aF0.07223601639270782
aF0.0487673282623291
aF0.06494998186826706
aF0.15234124660491943
aF0.06460395455360413
aF0.13545672595500946
aF0.1566186249256134
aF0.205779567360878
aF0.11067213118076324
aF0.07930786907672882
aF0.09538093209266663
aF0.1556074172258377
aF0.11399085819721222
aF0.09245060384273529
aF0.04796481132507324
aF0.09774575382471085
aF0.15584321320056915
aF0.05696675926446915
aF0.07988764345645905
aF0.14954590797424316
aF0.12572668492794037
aF0.11320377886295319
aF0.08026133477687836
aF0.11599151045084
aF0.08823664486408234
aF0.18252894282341003
aF0.07343284040689468
aF0.05509475991129875
aF0.07201290130615234
aF0.07493939250707626
aF0.10863542556762695
aF0.06429728865623474
aF0.07593671977519989
aF0.029675468802452087
aF0.038878925144672394
aF0.13895884156227112
aF0.08770451694726944
aF0.07198764383792877
aF0.052145734429359436
aF0.08017593622207642
aF0.03311941772699356
aF0.07033497840166092
aF0.04806847125291824
aF0.07927040010690689
aF0.03937347233295441
aF0.03872605040669441
aF0.06183386221528053
aF0.06749184429645538
aF0.07786353677511215
aF0.037281472235918045
aF0.10129116475582123
aF0.052187368273735046
aF0.07158781588077545
aF0.05056637153029442
aF0.06397590041160583
aF0.06787948310375214
aF0.10970330238342285
aF0.0588369220495224
aF0.05087462440133095
aF0.07373244315385818
aF0.09118802845478058
aF0.04684893786907196
aF0.05392099916934967
aF0.056068919599056244
aF0.07461141794919968
aF0.08412940800189972
aF0.07131364196538925
aF0.057118382304906845
aF0.07073593139648438
aF0.10020299255847931
aF0.07185950875282288
aF0.03276536986231804
aF0.14800506830215454
aF0.06013257056474686
aF0.03495335578918457
aF0.03164932504296303
aF0.08569132536649704
aF0.11777560412883759
aF0.037493206560611725
aF0.06470930576324463
aF0.025660036131739616
aF0.02799784019589424
aF0.03352930024266243
aF0.09616771340370178
aF0.0480242520570755
aF0.08614620566368103
aF0.06410884857177734
aF0.04339189827442169
aF0.09129883348941803
aF0.04725633189082146
aF0.09952157735824585
aF0.03826159983873367
aF0.05974471569061279
aF0.05652037262916565
aF0.07693987339735031
aF0.056907400488853455
aF0.07485964894294739
aF0.031738318502902985
aF0.015578503720462322
aF0.04842241853475571
aF0.02062499150633812
aF0.09186387062072754
aF0.09443461894989014
aF0.08506149053573608
aF0.04723402112722397
aF0.022161303088068962
aF0.05130641907453537
aF0.0916331484913826
aF0.10319256782531738
aF0.05244872719049454
aF0.10446115583181381
aF0.018975066021084785
aF0.049525752663612366
aF0.03620140254497528
aF0.06481055915355682
aF0.03198956325650215
aF0.08182217180728912
aF0.01872149109840393
aF0.06397265195846558
aF0.0743161290884018
aF0.05363353341817856
aF0.03830080106854439
aF0.005994581617414951
aF0.03666150942444801
aF0.04419730231165886
aF0.07760342210531235
aF0.051436200737953186
aF0.03942738473415375
aF0.06198723614215851
aF0.08593832701444626
aF0.08362962305545807
aF0.0395389162003994
aF0.023017916828393936
aF0.0414862334728241
aF0.03570608049631119
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3016698360443115
aF0.26846927404403687
aF0.10379929840564728
aF0.06616286188364029
aF0.05073387548327446
aF0.03350069001317024
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.3015315532684326
aF0.2572122812271118
aF0.12551161646842957
aF0.09828201681375504
aF0.08851435035467148
aF0.08007099479436874
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF0.0
aF4.0
aF4.0
as.