(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.14102056622505188
aF0.9507516026496887
aF0.9738923907279968
aF0.983781635761261
aF0.9883307218551636
aF0.9921875
asVtime/percentage_convergence_performance
p5
(lp6
F0.1448722779750824
aF0.9791367650032043
aF0.9992210865020752
aF1.0050323009490967
aF1.0086005926132202
aF1.0099259614944458
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.14052610099315643
aF0.9497626423835754
aF0.9692444801330566
aF0.9748813509941101
aF0.978342592716217
aF0.9796281456947327
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'train_log_interval'
p23
I10
sS'nologs'
p24
I00
sS'num_epochs'
p25
I5
sS'lr_sched_epochs'
p26
NsS'saveto'
p27
S'res/benchmark_small_final/'
p28
sS'lr_sched_factors'
p29
NsS'run_name'
p30
S'SGD/'
p31
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.2511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I50
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sbsVtraining/training_loss
p41
(lp42
F2.3020145893096924
aF2.2784390449523926
aF2.2284836769104004
aF2.085865020751953
aF1.6063801050186157
aF1.193551778793335
aF1.1551790237426758
aF1.054234266281128
aF1.046957015991211
aF0.6986786127090454
aF0.5879600048065186
aF0.6320419311523438
aF0.5682840347290039
aF0.3031812310218811
aF0.3595680594444275
aF0.4768586754798889
aF0.44623398780822754
aF0.35274240374565125
aF0.36992597579956055
aF0.4202480912208557
aF0.30455562472343445
aF0.36409175395965576
aF0.250111848115921
aF0.26402050256729126
aF0.26301899552345276
aF0.21359172463417053
aF0.2786717116832733
aF0.24342341721057892
aF0.27159398794174194
aF0.2534065246582031
aF0.2691163718700409
aF0.2369382083415985
aF0.23828406631946564
aF0.2747575640678406
aF0.2685823440551758
aF0.1477079689502716
aF0.3078489303588867
aF0.13682007789611816
aF0.2188454568386078
aF0.1644529104232788
aF0.1283574402332306
aF0.1578381359577179
aF0.16132216155529022
aF0.147646963596344
aF0.11961349844932556
aF0.2666073441505432
aF0.2070218324661255
aF0.22013622522354126
aF0.15209771692752838
aF0.12059605866670609
aF0.1605197787284851
aF0.15294474363327026
aF0.2175549864768982
aF0.16441963613033295
aF0.09294379502534866
aF0.21466432511806488
aF0.11279504746198654
aF0.13229042291641235
aF0.13440904021263123
aF0.15725542604923248
aF0.1193927675485611
aF0.09806782007217407
aF0.14862127602100372
aF0.1331319808959961
aF0.14344856142997742
aF0.09575594216585159
aF0.11581828445196152
aF0.1094217523932457
aF0.12478572130203247
aF0.10624121874570847
aF0.11201587319374084
aF0.1035049632191658
aF0.12947538495063782
aF0.2902336120605469
aF0.13413424789905548
aF0.19326801598072052
aF0.12952207028865814
aF0.10065436363220215
aF0.07804695516824722
aF0.09483864903450012
aF0.13117843866348267
aF0.13750776648521423
aF0.09556896984577179
aF0.059348076581954956
aF0.0676167756319046
aF0.12673911452293396
aF0.07833477854728699
aF0.04349556937813759
aF0.08083051443099976
aF0.054341115057468414
aF0.10522619634866714
aF0.05388341844081879
aF0.15414273738861084
aF0.05331317335367203
aF0.09212532639503479
aF0.11657988280057907
aF0.10011886060237885
aF0.1935541033744812
aF0.10288412123918533
aF0.1356220543384552
aF0.11572372913360596
aF0.10070820897817612
aF0.052015919238328934
aF0.11557690799236298
aF0.12140368670225143
aF0.039028361439704895
aF0.07032942771911621
aF0.025436973199248314
aF0.06039958447217941
aF0.08312590420246124
aF0.1292540431022644
aF0.06471668183803558
aF0.08011782169342041
aF0.12572571635246277
aF0.0457175113260746
aF0.01799522526562214
aF0.023879386484622955
aF0.07952162623405457
aF0.09220729768276215
aF0.05374618619680405
aF0.12845063209533691
aF0.04487474262714386
aF0.06017998233437538
aF0.05608826130628586
aF0.06793995201587677
aF0.08936212211847305
aF0.08799061179161072
aF0.1427379548549652
aF0.0803065374493599
aF0.0592016726732254
aF0.12241359055042267
aF0.07307517528533936
aF0.07442612946033478
aF0.06001630797982216
aF0.10093946754932404
aF0.03654472157359123
aF0.07382284104824066
aF0.06255561113357544
aF0.04642363637685776
aF0.08326531201601028
aF0.05805918574333191
aF0.13810615241527557
aF0.07536563277244568
aF0.05364237353205681
aF0.06630448997020721
aF0.06047333776950836
aF0.06657429784536362
aF0.092002272605896
aF0.09164850413799286
aF0.027581291273236275
aF0.13932958245277405
aF0.011585571803152561
aF0.03871956840157509
aF0.09470513463020325
aF0.01742839440703392
aF0.07515955716371536
aF0.09598159790039062
aF0.032807476818561554
aF0.05628972500562668
aF0.03112356923520565
aF0.046399008482694626
aF0.03833296149969101
aF0.04317082464694977
aF0.030863938853144646
aF0.028556756675243378
aF0.09292084723711014
aF0.02600640058517456
aF0.0668279230594635
aF0.05014811083674431
aF0.03222876787185669
aF0.023550953716039658
aF0.05555945634841919
aF0.12424411624670029
aF0.06134151667356491
aF0.0458725169301033
aF0.04021873697638512
aF0.07263921946287155
aF0.019581446424126625
aF0.0661756843328476
aF0.08900643140077591
aF0.12258172035217285
aF0.012840790674090385
aF0.015354611910879612
aF0.02510049380362034
aF0.019977521151304245
aF0.02369150146842003
aF0.06472145020961761
aF0.021029628813266754
aF0.026044201105833054
aF0.08456438779830933
aF0.032604798674583435
aF0.06364311277866364
aF0.0023944538552314043
aF0.014112832956016064
aF0.009264932945370674
aF0.028394285589456558
aF0.027162600308656693
aF0.042751967906951904
aF0.11048392951488495
aF0.028374996036291122
aF0.06270238757133484
aF0.03559358790516853
aF0.01948518306016922
aF0.015664907172322273
aF0.030567064881324768
aF0.032083213329315186
aF0.019903432577848434
aF0.04627196490764618
aF0.012037446722388268
aF0.026349112391471863
aF0.06984388083219528
aF0.008770184591412544
aF0.030027389526367188
aF0.01690574362874031
aF0.0488092266023159
aF0.022551553323864937
aF0.013799579814076424
aF0.008157206699252129
aF0.1187875047326088
aF0.02302989736199379
aF0.03535586968064308
aF0.026213621720671654
aF0.01883620023727417
aF0.008805169723927975
aF0.03247540071606636
aF0.04733709990978241
aF0.01599080115556717
aF0.0416472926735878
aF0.006789663806557655
aF0.033719953149557114
aF0.023123007267713547
aF0.07160794734954834
aF0.006432932801544666
aF0.012831361033022404
aF0.03198566287755966
asVcheckpoint/checkpoint_train_loss
p43
(lp44
F2.3011279106140137
aF0.16152174770832062
aF0.08612986654043198
aF0.052894409745931625
aF0.035944342613220215
aF0.02461015060544014
asVcheckpoint/checkpoint_test_loss
p45
(lp46
F2.3012073040008545
aF0.1544259488582611
aF0.09763303399085999
aF0.07788319885730743
aF0.06970588117837906
aF0.06767550855875015
asVhyperparams/learning_rate
p47
(lp48
F0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
asVtime/convergence_iterations
p49
(lp50
F0.0
aF0.0
aF0.0
aF3.0
aF3.0
aF3.0
as.