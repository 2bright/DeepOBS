(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.109375
aF0.9584652185440063
aF0.975969135761261
aF0.9835838675498962
aF0.9874406456947327
aF0.9901107549667358
asVtime/percentage_convergence_performance
p5
(lp6
F0.11020895838737488
aF0.9867830872535706
aF1.0014640092849731
aF1.0048284530639648
aF1.0068674087524414
aF1.0073771476745605
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.10690268874168396
aF0.957179605960846
aF0.9714201092720032
aF0.9746835231781006
aF0.9766613841056824
aF0.977155864238739
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'train_log_interval'
p23
I10
sS'nologs'
p24
I00
sS'num_epochs'
p25
I5
sS'lr_sched_epochs'
p26
NsS'saveto'
p27
S'res/benchmark_small_final/'
p28
sS'lr_sched_factors'
p29
NsS'run_name'
p30
S'SGD/'
p31
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.2511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I45
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sbsVtraining/training_loss
p41
(lp42
F2.3012752532958984
aF2.2856040000915527
aF2.2403953075408936
aF2.095569610595703
aF1.9010200500488281
aF1.8023324012756348
aF1.4302213191986084
aF0.7718635201454163
aF0.642605721950531
aF0.6130017042160034
aF0.5730369091033936
aF0.8247894644737244
aF0.41214096546173096
aF0.3189295828342438
aF0.6920924186706543
aF0.311970591545105
aF0.2730153203010559
aF0.5549156069755554
aF0.30162787437438965
aF0.24770180881023407
aF0.21589942276477814
aF0.3166239559650421
aF0.27565059065818787
aF0.2686006724834442
aF0.3050130605697632
aF0.3171674609184265
aF0.3641952872276306
aF0.22423070669174194
aF0.33750495314598083
aF0.21693041920661926
aF0.26505160331726074
aF0.11863893270492554
aF0.2183261513710022
aF0.2376495599746704
aF0.3066757619380951
aF0.14373049139976501
aF0.15315864980220795
aF0.13007420301437378
aF0.2286624014377594
aF0.29932233691215515
aF0.2503114342689514
aF0.2919939458370209
aF0.13348445296287537
aF0.3633043169975281
aF0.14275211095809937
aF0.09360942989587784
aF0.11970070004463196
aF0.09753439575433731
aF0.10294903814792633
aF0.11573290824890137
aF0.12342781573534012
aF0.18098261952400208
aF0.0605793222784996
aF0.09348046779632568
aF0.20930136740207672
aF0.11655668914318085
aF0.17484354972839355
aF0.1944396197795868
aF0.15696188807487488
aF0.07408782839775085
aF0.13065840303897858
aF0.16899003088474274
aF0.1021973192691803
aF0.08167892694473267
aF0.16387417912483215
aF0.16004543006420135
aF0.04727226495742798
aF0.17620795965194702
aF0.07966076582670212
aF0.1020175963640213
aF0.11601391434669495
aF0.21917276084423065
aF0.09966018050909042
aF0.1225937157869339
aF0.07975409924983978
aF0.12669649720191956
aF0.09679621458053589
aF0.12162034213542938
aF0.17711317539215088
aF0.06555908918380737
aF0.09565254300832748
aF0.12567204236984253
aF0.14258916676044464
aF0.11989498138427734
aF0.11206705868244171
aF0.03685823082923889
aF0.12410960346460342
aF0.12380078434944153
aF0.10831291973590851
aF0.07606744766235352
aF0.05115681141614914
aF0.09156687557697296
aF0.11350996792316437
aF0.15131478011608124
aF0.08596763759851456
aF0.043498799204826355
aF0.12226511538028717
aF0.0527576245367527
aF0.08721901476383209
aF0.047328218817710876
aF0.0474872961640358
aF0.0865495353937149
aF0.09971646219491959
aF0.07636590301990509
aF0.174340158700943
aF0.0948432981967926
aF0.04943137988448143
aF0.089619480073452
aF0.047611381858587265
aF0.04110199958086014
aF0.07263867557048798
aF0.05789399892091751
aF0.08325149118900299
aF0.13914841413497925
aF0.08506319671869278
aF0.08679811656475067
aF0.03145572543144226
aF0.0822250172495842
aF0.06423594802618027
aF0.08579178154468536
aF0.12319020926952362
aF0.05588209256529808
aF0.05598309263586998
aF0.08712305128574371
aF0.07649390399456024
aF0.07674611359834671
aF0.0852154940366745
aF0.09841504693031311
aF0.08813570439815521
aF0.1150602474808693
aF0.09419477730989456
aF0.08593283593654633
aF0.05033811554312706
aF0.07364755123853683
aF0.06629470735788345
aF0.08635027706623077
aF0.037886060774326324
aF0.05956311523914337
aF0.06187496334314346
aF0.03266230225563049
aF0.04380940645933151
aF0.07869651913642883
aF0.08754877746105194
aF0.0554618239402771
aF0.04643404856324196
aF0.0812121331691742
aF0.039446908980607986
aF0.03852921351790428
aF0.014672229066491127
aF0.01813489943742752
aF0.027872418984770775
aF0.047875337302684784
aF0.04427076503634453
aF0.025780297815799713
aF0.028395652770996094
aF0.08938165754079819
aF0.054365500807762146
aF0.05458532273769379
aF0.11296175420284271
aF0.11887969076633453
aF0.02343783713877201
aF0.10873450338840485
aF0.017805874347686768
aF0.021122902631759644
aF0.07795941084623337
aF0.09878682345151901
aF0.013556268997490406
aF0.030683886259794235
aF0.0505935437977314
aF0.045068785548210144
aF0.017894182354211807
aF0.05339352786540985
aF0.04850379377603531
aF0.011981535702943802
aF0.04061996936798096
aF0.034415360540151596
aF0.07704736292362213
aF0.09436192363500595
aF0.07072781026363373
aF0.015149682760238647
aF0.09433622658252716
aF0.0363052636384964
aF0.02477269619703293
aF0.01926400326192379
aF0.039381254464387894
aF0.0797581821680069
aF0.034787945449352264
aF0.06511874496936798
aF0.03772455453872681
aF0.08685871958732605
aF0.037653423845767975
aF0.05309491977095604
aF0.03975241258740425
aF0.01794194057583809
aF0.04325355961918831
aF0.04487884044647217
aF0.019376108422875404
aF0.04498099163174629
aF0.0380060076713562
aF0.056536827236413956
aF0.007921434938907623
aF0.024576259776949883
aF0.03937501460313797
aF0.01934518665075302
aF0.018448568880558014
aF0.013891313225030899
aF0.029624711722135544
aF0.01475362665951252
aF0.11190171539783478
aF0.01049044355750084
aF0.025874052196741104
aF0.03346730023622513
aF0.1282038390636444
aF0.008991915732622147
aF0.008937658742070198
aF0.045950811356306076
aF0.05190500244498253
aF0.026525791734457016
aF0.056220024824142456
aF0.014689096249639988
aF0.04805605858564377
aF0.03374921530485153
aF0.01944591850042343
aF0.022915296256542206
aF0.016828598454594612
aF0.021457523107528687
aF0.010499106720089912
aF0.06049969047307968
aF0.0890929251909256
aF0.031146440654993057
aF0.023101668804883957
aF0.007226570043712854
aF0.01096871867775917
aF0.052912160754203796
aF0.05121224373579025
asVcheckpoint/checkpoint_train_loss
p43
(lp44
F2.3012938499450684
aF0.14110803604125977
aF0.0807885155081749
aF0.056929752230644226
aF0.0418461449444294
aF0.0333327017724514
asVcheckpoint/checkpoint_test_loss
p45
(lp46
F2.3011159896850586
aF0.14601071178913116
aF0.09552720189094543
aF0.08121691644191742
aF0.07783303409814835
aF0.07705404609441757
asVhyperparams/learning_rate
p47
(lp48
F0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
aF0.25118860602378845
asVtime/convergence_iterations
p49
(lp50
F0.0
aF0.0
aF2.0
aF2.0
aF2.0
aF2.0
as.