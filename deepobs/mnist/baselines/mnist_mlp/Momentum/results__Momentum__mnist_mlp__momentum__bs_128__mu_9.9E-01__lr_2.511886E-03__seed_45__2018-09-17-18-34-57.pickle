(dp0
S'checkpoint/checkpoint_steps'
p1
(lp2
I0
aI1
aI2
aI3
aI4
aI5
asVcheckpoint/checkpoint_train_acc
p3
(lp4
F0.109375
aF0.9066455960273743
aF0.9626186490058899
aF0.9788370132446289
aF0.986155092716217
aF0.9868472814559937
asVtime/percentage_convergence_performance
p5
(lp6
F0.11020895838737488
aF0.9407012462615967
aF0.9884142875671387
aF0.998711347579956
aF1.0047264099121094
aF1.003706932067871
asVcheckpoint/checkpoint_test_acc
p7
(lp8
F0.10690268874168396
aF0.9124802350997925
aF0.9587618708610535
aF0.96875
aF0.9745846390724182
aF0.9735957384109497
asS'training/training_steps'
p9
(lp10
I1
aI11
aI21
aI31
aI41
aI51
aI61
aI71
aI81
aI91
aI101
aI111
aI121
aI131
aI141
aI151
aI161
aI171
aI181
aI191
aI201
aI211
aI221
aI231
aI241
aI251
aI261
aI271
aI281
aI291
aI301
aI311
aI321
aI331
aI341
aI351
aI361
aI371
aI381
aI391
aI401
aI411
aI421
aI431
aI441
aI451
aI461
aI471
aI481
aI491
aI501
aI511
aI521
aI531
aI541
aI551
aI561
aI571
aI581
aI591
aI601
aI611
aI621
aI631
aI641
aI651
aI661
aI671
aI681
aI691
aI701
aI711
aI721
aI731
aI741
aI751
aI761
aI771
aI781
aI791
aI801
aI811
aI821
aI831
aI841
aI851
aI861
aI871
aI881
aI891
aI901
aI911
aI921
aI931
aI941
aI951
aI961
aI971
aI981
aI991
aI1001
aI1011
aI1021
aI1031
aI1041
aI1051
aI1061
aI1071
aI1081
aI1091
aI1101
aI1111
aI1121
aI1131
aI1141
aI1151
aI1161
aI1171
aI1181
aI1191
aI1201
aI1211
aI1221
aI1231
aI1241
aI1251
aI1261
aI1271
aI1281
aI1291
aI1301
aI1311
aI1321
aI1331
aI1341
aI1351
aI1361
aI1371
aI1381
aI1391
aI1401
aI1411
aI1421
aI1431
aI1441
aI1451
aI1461
aI1471
aI1481
aI1491
aI1501
aI1511
aI1521
aI1531
aI1541
aI1551
aI1561
aI1571
aI1581
aI1591
aI1601
aI1611
aI1621
aI1631
aI1641
aI1651
aI1661
aI1671
aI1681
aI1691
aI1701
aI1711
aI1721
aI1731
aI1741
aI1751
aI1761
aI1771
aI1781
aI1791
aI1801
aI1811
aI1821
aI1831
aI1841
aI1851
aI1861
aI1871
aI1881
aI1891
aI1901
aI1911
aI1921
aI1931
aI1941
aI1951
aI1961
aI1971
aI1981
aI1991
aI2001
aI2011
aI2021
aI2031
aI2041
aI2051
aI2061
aI2071
aI2081
aI2091
aI2101
aI2111
aI2121
aI2131
aI2141
aI2151
aI2161
aI2171
aI2181
aI2191
aI2201
aI2211
aI2221
aI2231
aI2241
aI2251
aI2261
aI2271
aI2281
aI2291
aI2301
aI2311
aI2321
aI2331
aI2341
asVhyperparams/batch_size
p11
(lp12
F128.0
aF128.0
aF128.0
aF128.0
aF128.0
aF128.0
asS'args'
p13
ccopy_reg
_reconstructor
p14
(cargparse
Namespace
p15
c__builtin__
object
p16
Ntp17
Rp18
(dp19
S'wd'
p20
NsS'data_dir'
p21
S'data_tfobs'
p22
sS'nesterov'
p23
I00
sS'train_log_interval'
p24
I10
sS'nologs'
p25
I00
sS'num_epochs'
p26
I5
sS'lr_sched_epochs'
p27
NsS'saveto'
p28
S'res/benchmark_small_final/'
p29
sS'lr_sched_factors'
p30
NsS'mu'
p31
F0.99
sS'checkpoint_epochs'
p32
I1
sS'print_train_iter'
p33
I00
sS'lr'
p34
F0.002511886
sS'bs'
p35
I128
sS'pickle'
p36
I01
sS'random_seed'
p37
I45
sS'no_time'
p38
I00
sS'test_problem'
p39
S'mnist.mnist_mlp'
p40
sS'run_name'
p41
S'Momentum/'
p42
sbsVtraining/training_loss
p43
(lp44
F2.3012752532958984
aF2.3002543449401855
aF2.29975962638855
aF2.2942636013031006
aF2.2915945053100586
aF2.290154457092285
aF2.2836050987243652
aF2.2730612754821777
aF2.2559566497802734
aF2.2230825424194336
aF2.2101869583129883
aF2.1544041633605957
aF2.104368209838867
aF1.9630241394042969
aF1.8031771183013916
aF1.6147761344909668
aF1.3816328048706055
aF1.1063153743743896
aF0.934321403503418
aF0.7888935804367065
aF0.5519726276397705
aF0.5871044397354126
aF0.8782288432121277
aF0.8957396745681763
aF0.8675418496131897
aF0.6358118653297424
aF0.8086782693862915
aF0.7733850479125977
aF0.797410249710083
aF0.6467808485031128
aF0.7466419339179993
aF0.5539173483848572
aF0.46500250697135925
aF0.5449258089065552
aF0.7390536069869995
aF0.3517702519893646
aF0.49488961696624756
aF0.4371211528778076
aF0.48247307538986206
aF0.4498227834701538
aF0.48712149262428284
aF0.38141122460365295
aF0.2744041085243225
aF0.37543410062789917
aF0.36920464038848877
aF0.18672654032707214
aF0.2480950802564621
aF0.2565831243991852
aF0.23434847593307495
aF0.33746063709259033
aF0.2179776132106781
aF0.35764771699905396
aF0.2076341211795807
aF0.1914607286453247
aF0.3176945447921753
aF0.18725192546844482
aF0.17009437084197998
aF0.27241677045822144
aF0.22585299611091614
aF0.17203083634376526
aF0.19939552247524261
aF0.288709431886673
aF0.19382190704345703
aF0.0982729122042656
aF0.1826389729976654
aF0.19985976815223694
aF0.10034060478210449
aF0.25437241792678833
aF0.15445229411125183
aF0.21500107645988464
aF0.15151536464691162
aF0.27837830781936646
aF0.09818063676357269
aF0.17177632451057434
aF0.1670159101486206
aF0.14991092681884766
aF0.1518029272556305
aF0.1593417227268219
aF0.18236106634140015
aF0.1264955699443817
aF0.18966855108737946
aF0.17110763490200043
aF0.17198854684829712
aF0.17868076264858246
aF0.15966835618019104
aF0.07319653034210205
aF0.18647480010986328
aF0.1891324520111084
aF0.16909728944301605
aF0.14465534687042236
aF0.09750513732433319
aF0.11498647183179855
aF0.1464003026485443
aF0.14966969192028046
aF0.12590375542640686
aF0.05778670310974121
aF0.15286904573440552
aF0.15622328221797943
aF0.16543784737586975
aF0.1052851527929306
aF0.11762681603431702
aF0.1360781490802765
aF0.14784784615039825
aF0.11143803596496582
aF0.19755354523658752
aF0.113162100315094
aF0.08087624609470367
aF0.13675963878631592
aF0.042524199932813644
aF0.04362809658050537
aF0.13221967220306396
aF0.08222483843564987
aF0.1072218120098114
aF0.08310102671384811
aF0.08768616616725922
aF0.09086591005325317
aF0.039947278797626495
aF0.10977225750684738
aF0.04541422426700592
aF0.09909668564796448
aF0.17304837703704834
aF0.052822861820459366
aF0.08687879145145416
aF0.0655905082821846
aF0.12540075182914734
aF0.08125673979520798
aF0.09802253544330597
aF0.13464951515197754
aF0.11613801121711731
aF0.1578531563282013
aF0.09524610638618469
aF0.10225546360015869
aF0.03138910233974457
aF0.09332835674285889
aF0.06610201299190521
aF0.08863294124603271
aF0.0866294652223587
aF0.054738618433475494
aF0.08033578842878342
aF0.12155599892139435
aF0.04658655822277069
aF0.12146195769309998
aF0.07100311666727066
aF0.0495465025305748
aF0.0779786929488182
aF0.14856816828250885
aF0.05934258922934532
aF0.03760363161563873
aF0.03280699998140335
aF0.03359845280647278
aF0.03611627221107483
aF0.05237758904695511
aF0.09016500413417816
aF0.1086755096912384
aF0.030081607401371002
aF0.16925401985645294
aF0.10001213103532791
aF0.09620313346385956
aF0.20745432376861572
aF0.07984929531812668
aF0.08226446807384491
aF0.16799384355545044
aF0.031342923641204834
aF0.025839554145932198
aF0.11526522040367126
aF0.1151646226644516
aF0.031022541224956512
aF0.06662869453430176
aF0.07705968618392944
aF0.08625201135873795
aF0.031415075063705444
aF0.05167146772146225
aF0.0601947121322155
aF0.02049718052148819
aF0.029790561646223068
aF0.053072333335876465
aF0.07644510269165039
aF0.11649015545845032
aF0.08089789748191833
aF0.045480877161026
aF0.09522193670272827
aF0.04318857938051224
aF0.048245567828416824
aF0.0529959499835968
aF0.08293038606643677
aF0.12567318975925446
aF0.07148267328739166
aF0.086750328540802
aF0.08788478374481201
aF0.0872550904750824
aF0.07917498052120209
aF0.08799577504396439
aF0.07523991167545319
aF0.02290445566177368
aF0.04626324772834778
aF0.040781937539577484
aF0.034862641245126724
aF0.06964726746082306
aF0.04260306805372238
aF0.0850805789232254
aF0.010068142786622047
aF0.05700834095478058
aF0.02775447443127632
aF0.0226594265550375
aF0.03552956134080887
aF0.03199139982461929
aF0.05687796324491501
aF0.02884766086935997
aF0.07494693994522095
aF0.030490877106785774
aF0.01635398156940937
aF0.06384678184986115
aF0.1651281714439392
aF0.023769503459334373
aF0.024550558999180794
aF0.030837444588541985
aF0.058152612298727036
aF0.11348609626293182
aF0.06657050549983978
aF0.02126462385058403
aF0.07394393533468246
aF0.038480885326862335
aF0.01893073320388794
aF0.01083322148770094
aF0.020578481256961823
aF0.03345213085412979
aF0.03132199868559837
aF0.07859861105680466
aF0.07959114015102386
aF0.0234836395829916
aF0.05599213019013405
aF0.009439820423722267
aF0.009649598971009254
aF0.07987267524003983
aF0.08902007341384888
asVcheckpoint/checkpoint_train_loss
p45
(lp46
F2.3012938499450684
aF0.30422717332839966
aF0.1216721311211586
aF0.072713702917099
aF0.04813584312796593
aF0.04126221314072609
asVcheckpoint/checkpoint_test_loss
p47
(lp48
F2.3011159896850586
aF0.2868518531322479
aF0.1303950697183609
aF0.09463407099246979
aF0.08353877812623978
aF0.08173597604036331
asVhyperparams/momentum
p49
(lp50
F0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
aF0.9900000095367432
asVhyperparams/learning_rate
p51
(lp52
F0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
aF0.0025118859484791756
asVtime/convergence_iterations
p53
(lp54
F0.0
aF0.0
aF0.0
aF0.0
aF4.0
aF4.0
as.